### 날짜: 2023-05-08 13:57

### 주제:  미디어 관련 작업을 위한 프레임워크
---
### 메모: 
- AVFoundation은 다양한 Apple 플랫폼에서 사운드 및 영상 미디어의 처리, 제어, 가져오기 및 내보내기 등 광범위한 기능을 제공하는 프레임워크이다. 
- 이 프레임워크는 iOS, macOS, tvOS 및 watchOS에서 사용할 수 있으며, 기본적으로 오디오/비디오 플레이어를 만들거나, 복잡한 미디어 처리 및 분석 작업을 수행할 수 있다. 
- 이 프레임워크는 Objective-C interface를 제공하며, 이를 통해 시간 기반의 시청각 데이터를 상세하게 처리할 수 있다. 
#### AVFoundation stack on iOS
![avfoundation|500](https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/frameworksBlockDiagram_2x.png)
#### 개요
- AVFoundation 프레임워크에는 비디오 관련 API와 오디오 관련 API가 있다. 
	- 사운드 파일을 재생하려면 AVAudioPlayer를 사용할 수 있다. 
	- 오디오를 녹음하려면 AVAudioRecorder를 사용할 수 있다. 
- 또한 AVAudioSession을 사용하여 애플리케이션의 오디오 동작을 구성할 수도 있다. 
- AVFoundation 프레임워크가 미디어를 나타내는 데 사용하는 주요 클래스는 AVAsset이다. 이 구조를 이해하면 프레임워크 작동 방식을 이해하는 데 도움이 된다. 
#### Concurrent AVFoundation 
- AVFoundation의 콜백들(blocks, key-value observer, notification handlers)은 특정 스레드나 큐에서 실행되는 것이 보장되지 않는다. 대신 AVFoundation은 내부 작업을 수행하는 스레드나 큐에서 이러한 핸들러를 호출한다. 
#### AVFoundation의 주요 요소 
1.  **AVAsset**: 멀티미디어 데이터를 나타내는 객체로, 비디오와 오디오 트랙을 포함한다. AVAsset은 파일 또는 네트워크 스트림을 비롯한 다양한 소스에서 미디어 데이터를 나타낼 수 있다. AVAsset은 동작을 수행하기 위해 직접 사용되지 않지만, 여러 가지 다른 객체와 함께 사용하여 미디어 데이터를 검색, 조작 및 분석할 수 있다.
2.  **AVAssetTrack**: AVAsset 내의 개별 트랙(예: 비디오 트랙, 오디오 트랙, 자막 트랙 등)을 나타내는 객체이다. 트랙은 특정 미디어 유형(비디오, 오디오, 자막 등)에 대한 데이터를 포함하며, AVAsset에서 추출하거나 수정할 수 있다.
3.  AVPlayer: 미디어 재생을 처리하는 객체로, AVAsset의 인스턴스를 사용하여 미디어를 재생할 수 있습니다. AVPlayer는 미디어 재생을 제어하고 재생 상태를 관찰하는 메서드와 프로퍼티를 제공한다.
4.  **AVPlayerLayer**: AVPlayer와 함께 사용되어 미디어를 화면에 표시하는 CALayer 하위 클래스이다. 이 레이어는 AVPlayer의 출력을 화면에 렌더링한다.
5.  **AVPlayerItem**: AVPlayer와 함께 사용되어 재생할 AVAsset을 정의하는 객체입니다. AVPlayerItem은 재생 상태, 버퍼링 상태, 타임라인 및 기타 정보를 포함한다.
6.  **AVKit**: AVFoundation과 함께 사용되어 미디어 재생을 위한 사용자 인터페이스를 제공하는 프레임워크이다. AVKit을 사용하면 기본 제공된 플레이어 뷰 컨트롤러와 뷰를 사용하여 손쉽게 미디어를 재생하고 제어할 수 있다.
- AVFoundation을 사용하여 다양한 작업을 수행할 수 있다. 예를들어, 미디어 파일을 재생하거나 녹화, 미디어 파일에서 특정 프레임을 추출하거나, 비디오 트랜지션과 효과를 적용하거나, 미디어의 메타데이터를 조작하고 분석하는 등의 작업이 가능하다. 
#### AVFoundation의 주요 기능과 관련된 추가 구성 요소와 클래스들 
1.  **AVCaptureSession**: 오디오 및 비디오 데이터를 캡처하는 데 사용되는 중앙 객체입니다. AVCaptureSession은 데이터 소스(예: 카메라, 마이크)와 출력(예: 미디어 파일, 뷰)을 관리하고 조정합니다.
2.  **AVCaptureDevice**: 카메라, 마이크와 같은 물리적 캡처 장치를 나타내는 객체입니다. AVCaptureDevice는 장치의 설정 및 기능을 관리하고 AVCaptureSession에 연결하여 데이터를 캡처합니다.
3.  **AVCaptureInput**: 캡처 장치에서 캡처된 미디어 데이터를 AVCaptureSession에 전달하는 데 사용되는 객체입니다. AVCaptureDeviceInput 클래스는 AVCaptureDevice를 입력으로 사용하여 데이터를 캡처할 수 있게 해줍니다.
4.  **AVCaptureOutput**: 캡처된 미디어 데이터를 처리하거나 저장하는 데 사용되는 객체입니다. AVCaptureOutput의 서브클래스로는 AVCaptureStillImageOutput, AVCaptureMovieFileOutput, AVCaptureVideoDataOutput 등이 있습니다.
5.  **AVCaptureVideoPreviewLayer**: 카메라의 실시간 미리보기를 화면에 표시하는 데 사용되는 CALayer의 하위 클래스입니다.
6.  **AVMutableComposition**: AVAsset의 여러 세그먼트를 합성하고 편집하는 데 사용되는 객체입니다. AVMutableComposition은 여러 비디오 및 오디오 트랙을 조합하여 새로운 미디어 작업을 만드는 기능을 제공합니다.
7.  **AVMetadataItem**: 미디어 파일의 메타데이터를 나타내는 객체입니다. 이 클래스는 미디어 파일의 제목, 저자, 생성 날짜 등과 같은 정보를 저장하고 검색하는 데 사용됩니다.
8.  **AVAssetExportSession**: AVAsset을 다른 형식으로 내보내거나 변환하는 데 사용되는 객체입니다. 이 클래스를 사용하여 미디어 파일의 비트레이트를 변경하거나 다른 코덱으로 인코딩할 수 있습니다.
- 다양한 미디어 작업을 수행하는 데  필요한 AVFoundation의 주요 프로토콜들도 있다. 
	-  **AVAsychronousKeyValueLoading**
		- AVAsset 및 관련 객체의 비동기 속성 로딩을 관리하는 프로토콜이다. 
		- 이 프로토콜을 사용하면, 객체의 속성이 로드되기를 기다리지 않고도 미디어 작업을 시작할 수 있다. 
	- **AVAudioMixing**
		- 오디오 트랙 또는 오디오 노드의 믹싱을 관리하는 프로토콜이다
	- **AVVideoCompositing**
		- 비디오 트랙을 합성하는 데 사용되는 프로토콜이다.
	- **AVCaptureMetadataOutputObjectsDelegate**
		- 캡처된 미디어의 메타데이터를 처리하는 데 사용되는 프로토콜이다. 
### 출처(참고문헌) 
- https://developer.apple.com/documentation/avfoundation
- https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/00_Introduction.html#//apple_ref/doc/uid/TP40010188-CH1-SW3
  https://www.boostcourse.org/mo326/lecture/256088/?isDesc=false

### 연결문서 
- [[3. AVAsset]]


### Tag
- #IOS/AVFoundation